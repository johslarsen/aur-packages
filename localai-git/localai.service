[Unit]
Description=LocalAI server

# "%C" Cache directory root
# "%E" Configuration directory root
# "%S" State directory root
# "%T" Directory for temporary files

[Service]
Type=simple
WorkingDirectory=%h
Restart=on-failure

PrivateTmp=yes

# enabled extra backends
Environment=EXTRA_BACKENDS="bark diffusers rerankers sentencetransformers transformers transformers-musicgen"
# disabled: autogptq coqui exllama exllama2 mamba openvoice parler-tts petals vall-e-x
Environment=EXTERNAL_GRPC_BACKENDS="\
bark:%C/localai/backend_extra/bark/run.sh,\
diffusers:%C/localai/backend_extra/diffusers/run.sh,\
rerankers:%C/localai/backend_extra/rerankers/run.sh,\
sentencetransformers:%C/localai/backend_extra/sentencetransformers/run.sh,\
transformers:%C/localai/backend_extra/transformers/run.sh,\
transformers-musicgen:%C/localai/backend_extra/transformers-musicgen/run.sh"

# default environment and local env
EnvironmentFile=/usr/share/localai/localai.env
EnvironmentFile=-%E/localai/.env

# create directories
ExecStartPre=mkdir -p \
  %E/localai \
  %S/localai/models/config \
  %C/localai/backend_assets \
  %C/localai/backend_extra \
  %T/localai/audio \
  %T/localai/images \
  %T/localai/upload

# generate enabled python extra backends
ExecStartPre=bash -c "\
  cd %C/localai/backend_extra; \
  for b in $EXTRA_BACKENDS; do \
    if test ! -e $b; then \
      cp -r /usr/share/localai/python/$b %C/localai/backend_extra; \
      make -C $b; \
    fi; \
  done"

# start server
ExecStart=/usr/bin/localai run \
  --config-path "%E/localai" \
  --localai-config-dir "%E/localai" \
  --models-path "%S/localai/models" \
  --backend-assets-path "%C/localai/backend_assets" \
  --audio-path "%T/localai/audio" \
  --image-path "%T/localai/images" \
  --upload-path "%T/localai/upload"

[Install]
WantedBy=default.target
